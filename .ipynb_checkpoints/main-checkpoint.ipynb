{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Auto Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Autoencoder import layers, autoencoder, callbacks, dataset, trainloop\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import tensorflow as tf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(model, train_ds, validation_ds, loss, optimizer, model_ckpt, history_log):\n",
    "    train = trainloop.Train(model, loss, optimizer, model_ckpt, history_log)\n",
    "    trained_model, history = train.trainLoop(train_ds, validation_ds, debug = True)\n",
    "    \n",
    "    return trained_model, history "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\fashionmnist\\Autoencoder\\dataset.py:74: MatplotlibDeprecationWarning: Passing non-integers as three-element position specification is deprecated since 3.3 and will be removed two minor releases later.\n",
      "  ax = plt.subplot(len(augmented_image) / columns + 1, columns, i + 1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 30 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version: 2.4.0\n",
      "Eager execution: True\n",
      "No checkpoint provided, begin training\n",
      "Learning rate: <tf.Variable 'learning_rate:0' shape=() dtype=int32, numpy=2>\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['AutoEncoder/dense/kernel:0', 'AutoEncoder/dense/bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "A non-persistent GradientTape can only be used tocompute one set of gradients (or jacobians)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-395299e8c67e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mhistory_log\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"history\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0mtrained_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_ds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_ds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_ckpt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhistory_log\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-2-dfbff3a9baac>\u001b[0m in \u001b[0;36mmain\u001b[1;34m(model, train_ds, validation_ds, loss, optimizer, model_ckpt, history_log)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_ds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_ds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_ckpt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhistory_log\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mtrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainloop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_ckpt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhistory_log\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mtrained_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainLoop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_ds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdebug\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtrained_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\fashionmnist\\Autoencoder\\trainloop.py\u001b[0m in \u001b[0;36mtrainLoop\u001b[1;34m(self, train, validation, epochs, debug)\u001b[0m\n\u001b[0;32m     38\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Learning rate: {self.optimizer.learning_rate}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m             \u001b[0mtrain_log\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m             \u001b[0mvalid_log\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalid_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m             \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_log\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_log\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\cs_ftmle\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    822\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mRUN_FUNCTIONS_EAGERLY\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    823\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf_function_call\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"eager\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 824\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    825\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\cs_ftmle\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mbound_method_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   3880\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mtf_inspect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3881\u001b[0m         \u001b[0mwrapped_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_unbound_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3882\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mwrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweak_instance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3884\u001b[0m     \u001b[1;31m# If __wrapped__ was replaced, then it is always an unbound function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\fashionmnist\\Autoencoder\\trainloop.py\u001b[0m in \u001b[0;36mtrain_step\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     75\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m             \u001b[0mgradients\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mweights\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mlayers\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mweights\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mweights\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mlayers\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mweights\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\cs_ftmle\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[1;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[0;32m   1025\u001b[0m     \"\"\"\n\u001b[0;32m   1026\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tape\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1027\u001b[1;33m       raise RuntimeError(\"A non-persistent GradientTape can only be used to\"\n\u001b[0m\u001b[0;32m   1028\u001b[0m                          \"compute one set of gradients (or jacobians)\")\n\u001b[0;32m   1029\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_recording\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: A non-persistent GradientTape can only be used tocompute one set of gradients (or jacobians)"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    (X_train, y_train), (X_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "    \n",
    "        \n",
    "    ds = dataset.Dataset(X_train, y_train)\n",
    "    train_ds, validation_ds = ds.dataset(True)\n",
    "    plt.show() \n",
    "    \n",
    "    model = autoencoder.AutoEncoder()\n",
    "    loss = layers.Losses()\n",
    "    optimizer = tf.keras.optimizers.Adam()\n",
    "    model_ckpt = \"ckpt\"\n",
    "    history_log = \"history\"\n",
    "    \n",
    "    trained_model, history = main(model, train_ds, validation_ds, loss, optimizer, model_ckpt, history_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Classifcation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cs_ftmle] *",
   "language": "python",
   "name": "conda-env-cs_ftmle-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
